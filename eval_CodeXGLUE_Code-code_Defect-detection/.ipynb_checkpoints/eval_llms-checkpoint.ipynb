{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2192afc3-647d-4ce4-82dc-e8798a082315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, random\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2425cec0-1ed2-4a45-bcea-2d709f3b4265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temperature = 0.0\n",
    "temperature = 1.0\n",
    "#model = \"gpt-4o-mini-2024-07-18\"\n",
    "model = \"ft:gpt-4o-mini-2024-07-18:uedin:semantic-inequiv-bob-run-0-round-6-generation-0:AyS2gJFd\"\n",
    "max_tokens = 256\n",
    "#n = 1\n",
    "n = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "03d5fab7-fbe7-475a-b278-a82ced1f7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename_base = \"./gpt-4o-mini\"\n",
    "filename_base = \"./sinq-gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4d7a6882-873e-4a06-8d04-26d7a5834f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_to_openai = filename_base+\"_to_openai.jsonl\"\n",
    "filename_from_openai = filename_base+\"_from_openai.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "70074403-553a-4530-a83b-8e807170d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \\\n",
    "\"\"\"You are an expert computer scientist. Your task is to take a C/C++ function and determine whether it contains a security vulnerability.\n",
    "Write your output the following JSON format:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"vulnerability\": true or false\n",
    "}\n",
    "```\n",
    "\n",
    "Do not write anything else.\n",
    "\"\"\"\n",
    "\n",
    "def user_message_fn_0(example):\n",
    "    return f\"\"\"Function:\n",
    "\n",
    "```\n",
    "{example[\"func\"]}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d4e36820-2a1d-4fe7-840d-57a64530c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_to_openai_api_format(example):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}, \n",
    "                {\"role\": \"user\", \"content\": user_message_fn_0(example)}]\n",
    "    rv = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"n\": n,\n",
    "        \"response_format\": { \"type\": \"json_object\" }\n",
    "    }\n",
    "    return json.dumps(rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b8957b20-37f4-425f-ae15-b0e3e89d7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "with open(\"./dataset/test.jsonl\") as in_fs:\n",
    "    for line in in_fs:\n",
    "        dataset.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "25df534b-57d8-4f2a-9bb9-73d62e3018ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename_to_openai, \"w\") as out_fs:\n",
    "    for example in dataset:\n",
    "        example[\"llm_request\"] = example_to_openai_api_format(example)\n",
    "        print(example[\"llm_request\"], file=out_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "22d59c44-8622-4f1b-82cd-794261b929b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3b524112-48ca-48ff-9334-b828ff80bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_from_openai = dict()\n",
    "with open(filename_from_openai, \"r\") as in_fs:\n",
    "    for line in in_fs:\n",
    "        response_k, response_v = json.loads(line)\n",
    "        response_k_str = json.dumps(response_k)\n",
    "        responses_from_openai[response_k_str] = response_v\n",
    "\n",
    "for example in dataset:\n",
    "    if (\"llm_request\" in example) and (example[\"llm_request\"] in responses_from_openai):\n",
    "        example[\"llm_response\"] = responses_from_openai[example[\"llm_request\"]]\n",
    "        example[\"llm_prediction\"] = []\n",
    "        for k, choice in enumerate(example[\"llm_response\"][\"choices\"]):\n",
    "            parsed = json.loads(choice[\"message\"][\"content\"])\n",
    "            example[\"llm_prediction\"].append(parsed[\"vulnerability\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "934dc2a9-bee6-4fc4-8b70-1fe4bbf4369f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ft:gpt-4o-mini-2024-07-18:uedin:semantic-inequiv-bob-run-0-round-6-generation-0:AyS2gJFd, n: 9, temperature: 1.0, evaluated examples: 2732, num. correct: 1531, accuracy: 0.5603953147877013\n"
     ]
    }
   ],
   "source": [
    "num_examples = 0\n",
    "num_correct = 0\n",
    "\n",
    "for example in dataset:\n",
    "    if \"llm_request\" in example:\n",
    "        num_examples += 1\n",
    "        majority_prediction = (np.array(example[\"llm_prediction\"]).mean() >= 0.5)\n",
    "        if example[\"target\"] == majority_prediction:\n",
    "            num_correct += 1\n",
    "\n",
    "accuracy = float(num_correct) / num_examples\n",
    "print(f\"Model: {model}, n: {n}, temperature: {temperature}, evaluated examples: {num_examples}, num. correct: {num_correct}, accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "58c85a35-3784-4018-8dc1-73a7e9dd4d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: gpt-4o-mini-2024-07-18, n: 1, temperature: 0.0, evaluated examples: 2732, num. correct: 1509, accuracy: 0.5523426061493412\n",
    "# Model: ft:gpt-4o-mini-2024-07-18:uedin:semantic-inequiv-bob-run-0-round-6-generation-0:AyS2gJFd, n: 1, temperature: 0.0, evaluated examples: 2732, num. correct: 1519, accuracy: 0.5560029282576867\n",
    "\n",
    "# Model: gpt-4o-mini-2024-07-18, n: 9, temperature: 1.0, evaluated examples: 2732, num. correct: 1506, accuracy: 0.5512445095168375\n",
    "# Model: ft:gpt-4o-mini-2024-07-18:uedin:semantic-inequiv-bob-run-0-round-6-generation-0:AyS2gJFd, n: 9, temperature: 1.0, evaluated examples: 2732, num. correct: 1531, accuracy: 0.5603953147877013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e49451-8843-41dc-a029-a12869ff5869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
