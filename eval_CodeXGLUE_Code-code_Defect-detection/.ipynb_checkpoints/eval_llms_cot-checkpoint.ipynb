{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2192afc3-647d-4ce4-82dc-e8798a082315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, random\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "import mistune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2425cec0-1ed2-4a45-bcea-2d709f3b4265",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.6\n",
    "#model = \"gpt-4o-mini-2024-07-18\"\n",
    "model = \"ft:gpt-4o-mini-2024-07-18:uedin:semantic-inequiv-bob-run-0-round-6-generation-0:AyS2gJFd\"\n",
    "max_tokens = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03d5fab7-fbe7-475a-b278-a82ced1f7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename_base = \"./gpt-4o-mini\"\n",
    "filename_base = \"./sinq-gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d7a6882-873e-4a06-8d04-26d7a5834f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_to_openai = filename_base+\"_to_openai.jsonl\"\n",
    "filename_from_openai = filename_base+\"_from_openai.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70074403-553a-4530-a83b-8e807170d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \\\n",
    "\"\"\"You are an expert computer scientist. Your task is to take a C/C++ function and determine whether it contains a security vulnerability.\n",
    "Think step by step before writing your program. Use the following Markdown format, making sure that the following sections are delimited by level 1 headings, since they will have to be automatically parsed:\n",
    "# Analysis\n",
    "step by step analysis. This section can include sub-headings and code blocks\n",
    "# Output\n",
    "```json\n",
    "{\n",
    "  \"vulnerability\": true or false\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "def user_message_fn_0(example):\n",
    "    return f\"\"\"Function:\n",
    "\n",
    "```\n",
    "{example[\"func\"]}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d4e36820-2a1d-4fe7-840d-57a64530c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_to_openai_api_format(example):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}, \n",
    "                {\"role\": \"user\", \"content\": user_message_fn_0(example)}]\n",
    "    rv = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"n\": 1,\n",
    "        #\"response_format\": { \"type\": \"json_object\" }\n",
    "    }\n",
    "    return json.dumps(rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8957b20-37f4-425f-ae15-b0e3e89d7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "with open(\"./dataset/test.jsonl\") as in_fs:\n",
    "    for line in in_fs:\n",
    "        dataset.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25df534b-57d8-4f2a-9bb9-73d62e3018ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename_to_openai, \"w\") as out_fs:\n",
    "    for example in dataset:\n",
    "        example[\"llm_request\"] = example_to_openai_api_format(example)\n",
    "        print(example[\"llm_request\"], file=out_fs)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "22d59c44-8622-4f1b-82cd-794261b929b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b524112-48ca-48ff-9334-b828ff80bd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid response\n"
     ]
    }
   ],
   "source": [
    "responses_from_openai = dict()\n",
    "with open(filename_from_openai, \"r\") as in_fs:\n",
    "    for line in in_fs:\n",
    "        response_k, response_v = json.loads(line)\n",
    "        response_k_str = json.dumps(response_k)\n",
    "        responses_from_openai[response_k_str] = response_v\n",
    "\n",
    "markdown = mistune.create_markdown(renderer='ast')\n",
    "for example in dataset:\n",
    "    if (\"llm_request\" in example) and (example[\"llm_request\"] in responses_from_openai):\n",
    "        example[\"llm_response\"] = responses_from_openai[example[\"llm_request\"]]\n",
    "        content = example[\"llm_response\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "        try:\n",
    "            parsed_markdown = markdown(content)\n",
    "            output_i = [i for i, e in enumerate(parsed_markdown) if (e['type'] == \"heading\") and (e[\"children\"][0][\"raw\"] == \"Output\")][0]\n",
    "            output_code_block = [e[\"raw\"] for e in parsed_markdown[output_i:] if (e['type'] == \"block_code\") and (\"attrs\" in e) and (e[\"attrs\"][\"info\"]==\"json\")][0]\n",
    "            parsed = json.loads(output_code_block)\n",
    "            example[\"llm_prediction\"] = parsed[\"vulnerability\"]\n",
    "        except:\n",
    "            print(\"Invalid response\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "934dc2a9-bee6-4fc4-8b70-1fe4bbf4369f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ft:gpt-4o-mini-2024-07-18:uedin:semantic-inequiv-bob-run-0-round-6-generation-0:AyS2gJFd, evaluated examples: 2732, num. correct: 1290, accuracy: 0.47218155197657397\n"
     ]
    }
   ],
   "source": [
    "num_examples = 0\n",
    "num_correct = 0\n",
    "\n",
    "for example in dataset:\n",
    "    if \"llm_request\" in example:\n",
    "        num_examples += 1\n",
    "        if (\"llm_prediction\" in example) and (example[\"target\"] == example[\"llm_prediction\"]):\n",
    "            num_correct += 1\n",
    "\n",
    "accuracy = float(num_correct) / num_examples\n",
    "print(f\"Model: {model}, evaluated examples: {num_examples}, num. correct: {num_correct}, accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "58c85a35-3784-4018-8dc1-73a7e9dd4d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: gpt-4o-mini-2024-07-18, evaluated examples: 2732, num. correct: 1303, accuracy: 0.4769399707174231\n",
    "# Model: ft:gpt-4o-mini-2024-07-18:uedin:semantic-inequiv-bob-run-0-round-6-generation-0:AyS2gJFd, evaluated examples: 2732, num. correct: 1290, accuracy: 0.47218155197657397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d3a6ca5c-41e5-49da-b629-da70861bec71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2732"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd8c182-b188-46bc-b3c8-e50cfb14db6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
